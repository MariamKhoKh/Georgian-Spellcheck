{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "182f3882",
      "metadata": {
        "id": "182f3882"
      },
      "source": [
        "# Georgian Spellchecker - Data Collection and Training\n",
        "\n",
        "Character-level Seq2Seq model for Georgian spelling correction\n",
        "\n",
        "## Overview\n",
        "Complete pipeline for building a Georgian spellchecker with:\n",
        "1. Data Collection (Wikipedia)\n",
        "2. Synthetic Error Generation\n",
        "3. Model Architecture (Encoder-Decoder + Attention)\n",
        "4. Training Loop\n",
        "5. Model Evaluation and Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d948e2c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d948e2c9",
        "outputId": "a9352728-8cfa-43a2-a0b3-965f7a6b9c18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.9.0+cu126\n",
            "CUDA: True\n"
          ]
        }
      ],
      "source": [
        "import re, json, bz2, random, time\n",
        "import xml.etree.ElementTree as ET\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Set\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model import Seq2SeqSpellchecker, CharacterVocabulary, count_parameters\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "\n",
        "Path('data').mkdir(exist_ok=True)\n",
        "Path('checkpoints').mkdir(exist_ok=True)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a62ca9ff",
      "metadata": {
        "id": "a62ca9ff"
      },
      "source": [
        "## 1. Data Collection\n",
        "\n",
        "We collect Georgian words from Wikipedia dump."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fda3ef96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fda3ef96",
        "outputId": "4b26cdf9-e9a6-4b0d-e2c7-19e64361a98e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Georgian Wikipedia Processing Pipeline\n",
            "Downloading Georgian wikipedia dump...\n",
            "URL: https://dumps.wikimedia.org/kawiki/latest/kawiki-latest-pages-articles.xml.bz2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 227M/227M [00:50<00:00, 4.50MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download complete: data/kawiki-latest-pages-articles.xml.bz2\n",
            "extracting text from wikipedia dump...\n",
            "  Processed 1000 articles, found 0 unique words...\n",
            "  Processed 2000 articles, found 0 unique words...\n",
            "  Processed 3000 articles, found 0 unique words...\n",
            "  Processed 4000 articles, found 0 unique words...\n",
            "  Processed 5000 articles, found 0 unique words...\n",
            "Extracted text from 5000 articles\n",
            "\n",
            "Extracting Georgian words from articles...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 411/5000 [00:00<00:01, 4011.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 24285 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 1191/5000 [00:00<00:03, 1148.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 62168 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 1574/5000 [00:01<00:02, 1319.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 76969 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 2193/5000 [00:01<00:02, 1203.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 99706 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▋    | 2814/5000 [00:02<00:01, 1323.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 115691 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 3250/5000 [00:02<00:01, 1303.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 125273 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 3628/5000 [00:03<00:01, 1104.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 138041 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 4389/5000 [00:03<00:00, 1908.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 144968 unique words found...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:03<00:00, 1403.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 152234 unique words found...\n",
            "  Progress: 157080 unique words found...\n",
            "\n",
            "Extraction complete: 157080 unique words\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATASET STATISTICS\n",
            "Total unique words:      157,080\n",
            "Character vocabulary:    33\n",
            "Shortest word length:    2\n",
            "Longest word length:     20\n",
            "Average word length:     8.9\n",
            "\n",
            "Most common characters:  აიესროლმნდბვუთტგკშხქ\n",
            "Sample words (first 30):\n",
            " 1. აა\n",
            " 2. ააბენრაას\n",
            " 3. ააგდო\n",
            " 4. ააგეს\n",
            " 5. ააგო\n",
            " 6. ააგორა\n",
            " 7. ააგრეთვე\n",
            " 8. აადგილი\n",
            " 9. აადვილებდა\n",
            "10. აადვილებს\n",
            "11. აავადებდნენ\n",
            "12. აავადებს\n",
            "13. აავი\n",
            "14. აავსო\n",
            "15. ააიმას\n",
            "16. ააიპ\n",
            "17. ააკანალის\n",
            "18. ააკერებდნენ\n",
            "19. ააკლებინა\n",
            "20. აალაპარაკა\n",
            "21. აალებადია\n",
            "22. აალებული\n",
            "23. აალი\n",
            "24. აალსტი\n",
            "25. აალტო\n",
            "26. აალტოზე\n",
            "27. აალტომ\n",
            "28. აალტონენი\n",
            "29. აალტოს\n",
            "30. აალტოში\n",
            "\n",
            "Saved word list: data/georgian_words.txt (157080 words)\n",
            "Saved vocabulary: data/char_vocab.json (33 characters)\n",
            "Saved metadata: data/metadata.json\n"
          ]
        }
      ],
      "source": [
        "from wikipedia_collector import GeorgianWikipediaProcessor\n",
        "\n",
        "# use GeorgianWikipediaProcessor class from wikipedia_collector.py\n",
        "processor = GeorgianWikipediaProcessor(output_dir='data')\n",
        "processor.process_dump(max_articles=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e9a467",
      "metadata": {
        "id": "22e9a467"
      },
      "source": [
        "## 2. Synthetic Error Generation\n",
        "\n",
        "Generate realistic spelling errors:\n",
        "- Substitution (40%): keyboard-adjacent keys\n",
        "- Deletion (25%)\n",
        "- Insertion (15%)\n",
        "- Swap (15%)\n",
        "- Repetition (5%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f07c7ded",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f07c7ded",
        "outputId": "ec41632f-cb14-4297-8075-d3940b500846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating training pairs...\n",
            "Words: 157080\n",
            "Samples per word: 3\n",
            "Expected dataset size: ~471,240\n",
            "  Processed 10,000 words, generated 30,000 pairs...\n",
            "  Processed 20,000 words, generated 60,000 pairs...\n",
            "  Processed 30,000 words, generated 90,000 pairs...\n",
            "  Processed 40,000 words, generated 120,000 pairs...\n",
            "  Processed 50,000 words, generated 150,000 pairs...\n",
            "  Processed 60,000 words, generated 180,000 pairs...\n",
            "  Processed 70,000 words, generated 210,000 pairs...\n",
            "  Processed 80,000 words, generated 240,000 pairs...\n",
            "  Processed 90,000 words, generated 270,000 pairs...\n",
            "  Processed 100,000 words, generated 300,000 pairs...\n",
            "  Processed 110,000 words, generated 330,000 pairs...\n",
            "  Processed 120,000 words, generated 360,000 pairs...\n",
            "  Processed 130,000 words, generated 390,000 pairs...\n",
            "  Processed 140,000 words, generated 420,000 pairs...\n",
            "  Processed 150,000 words, generated 450,000 pairs...\n",
            "\n",
            " Generated 471,240 training pairs\n",
            "SAMPLE TRAINING PAIRS\n",
            "Input (Corrupted)              → Target (Correct)              \n",
            "✗ ხაზისწაგანაა                 → ხაზისაგანაა                 \n",
            "✗ ყგსხვლის                     → გასხვლის                    \n",
            "✗ კუმამოტს                     → კუმამოტოს                   \n",
            "✗ ხაბძთაში                     → ხანძთაში                    \n",
            "✗ ალტოს                        → აალტოს                      \n",
            "✗ შახლვეკის                    → შახოვსკის                   \n",
            "✗ სირმული                      → სიღრმული                    \n",
            "✗ განძაესცვა                   → განძარცვა                   \n",
            "✗ ესიგეინის                    → ეისტეინის                   \n",
            "✗ ბრძანეაბსა                   → ბრძანებასა                  \n",
            "✗ ტაოს                         → ტასო                        \n",
            "✗ მოახდნიოით                   → მოახდინოთ                   \n",
            "✗ განსაზვღრებგაა               → განსაზღვრებაა               \n",
            "✓ ჩაერიოს                      → ჩაერიოს                     \n",
            "✗ ვიპურის                      → ვიიპურის                    \n",
            "✗ ვლესიარიუსის                 → ველისარიუსის                \n",
            "✗ კინწმაოტგრაფებია             → კინემატოგრაფებია            \n",
            "✗ ნატიოქია                     → ანტიოქია                    \n",
            "✗ დიქტგატუის                   → დიქტატურის                  \n",
            "✗ ანთეოოპლოგი                  → ანთროპოლოგი                 \n",
            "✗ ლუქრა                        → ლუარა                       \n",
            "✗ მედიცინაიი                   → მედიცინაში                  \n",
            "✗ იზმსი                        → იამსი                       \n",
            "✗ დარძალვას                    → დაკრძალვას                  \n",
            "✓ მიო                          → მიო                         \n",
            "✗ ტელემაუწგებლოაბ              → ტელემაუწყებლობა             \n",
            "✗ გრავიტაციაასც                → გრავიტაციასაც               \n",
            "✗ ამოსუნთქოს                   → ამოსუნთქვის                 \n",
            "✗ ემრე                         → მერე                        \n",
            "✗ ისფან                        → ისგან                       \n",
            "ERROR STATISTICS\n",
            "Total pairs:           471,240\n",
            "Unchanged (correct):   74,188 (15.7%)\n",
            "Corrupted:             397,052 (84.3%)\n",
            "\n",
            "Error type estimates:\n",
            "  Deletions:           117,316 (29.5%)\n",
            "  Insertions:          91,771 (23.1%)\n",
            "  Substitutions/Swaps: 187,965 (47.3%)\n",
            "\n",
            "Saved dataset to data/training_pairs.txt\n"
          ]
        }
      ],
      "source": [
        "from error_generator import GeorgianErrorGenerator\n",
        "\n",
        "# use the GeorgianErrorGenerator class from error_generator.py\n",
        "with open('data/georgian_words.txt', 'r', encoding='utf-8') as f:\n",
        "    words = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "generator = GeorgianErrorGenerator()\n",
        "dataset = generator.generate_dataset(words, samples_per_word=3, seed=42)\n",
        "\n",
        "generator.show_examples(dataset, n=30)\n",
        "generator.analyze_errors(dataset)\n",
        "generator.save_dataset(dataset, 'data/training_pairs.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d057fc0",
      "metadata": {
        "id": "2d057fc0"
      },
      "source": [
        "## 3. Model Architecture\n",
        "\n",
        "**Encoder-Decoder with Attention**:\n",
        "- Encoder: Bidirectional LSTM (reads corrupted word)\n",
        "- Attention: Focuses on relevant input positions\n",
        "- Decoder: LSTM (generates corrected word)\n",
        "\n",
        "Architecture imported from `model.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98261671",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98261671",
        "outputId": "3d23dfe3-31ce-42f1-9cda-0448f0e0539f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 37\n",
            "Parameters: 25,158,693\n"
          ]
        }
      ],
      "source": [
        "vocab = CharacterVocabulary()\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "\n",
        "model = Seq2SeqSpellchecker(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=128,      \n",
        "    encoder_dim=256,       \n",
        "    decoder_dim=256,        \n",
        "    attention_dim=128,      \n",
        "    num_layers=2,          \n",
        "    dropout=0.3\n",
        ")\n",
        "\n",
        "print(f\"Parameters: {count_parameters(model):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d835d97c",
      "metadata": {
        "id": "d835d97c"
      },
      "source": [
        "## 4. Training Pipeline\n",
        "\n",
        "Configuration:\n",
        "- Batch size: 128\n",
        "- Learning rate: 0.001\n",
        "- Epochs: 20 (with early stopping)\n",
        "- Train/Val split: 90/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f849cd64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f849cd64",
        "outputId": "24feeae9-0c21-49e0-a789-0a08c32492fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 424,116, Val: 47,124\n"
          ]
        }
      ],
      "source": [
        "class SpellingDataset(Dataset):\n",
        "    def __init__(self, data_path, vocab):\n",
        "        self.vocab = vocab\n",
        "        self.pairs = []\n",
        "\n",
        "        with open(data_path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    inp, tgt = line.strip().split('\\t')\n",
        "                    self.pairs.append((inp, tgt))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inp, tgt = self.pairs[idx]\n",
        "        src = torch.tensor(self.vocab.encode(inp))\n",
        "        trg = torch.tensor([self.vocab.sos_idx] +\n",
        "                          self.vocab.encode(tgt) +\n",
        "                          [self.vocab.eos_idx])\n",
        "        return src, trg\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "    src_lengths = torch.tensor([len(s) for s in src_batch])\n",
        "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
        "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=0)\n",
        "    return src_padded, src_lengths, trg_padded\n",
        "\n",
        "# load data\n",
        "full_dataset = SpellingDataset('data/training_pairs.txt', vocab)\n",
        "\n",
        "# split\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "train_size = len(full_dataset) - val_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "# create loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=128,\n",
        "                         shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128,\n",
        "                       shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train: {len(train_dataset):,}, Val: {len(val_dataset):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5767d100",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5767d100",
        "outputId": "a44df6f5-2c81-48e4-c214-abe438d1ca2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/30\n",
            "  Batch 500/3314, Loss: 0.7270\n",
            "  Batch 1000/3314, Loss: 0.7078\n",
            "  Batch 1500/3314, Loss: 0.6113\n",
            "  Batch 2000/3314, Loss: 0.5910\n",
            "  Batch 2500/3314, Loss: 0.5693\n",
            "  Batch 3000/3314, Loss: 0.5949\n",
            "Train Loss: 0.7177, Val Loss: 0.9481\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 2/30\n",
            "  Batch 500/3314, Loss: 0.4928\n",
            "  Batch 1000/3314, Loss: 0.5911\n",
            "  Batch 1500/3314, Loss: 0.4825\n",
            "  Batch 2000/3314, Loss: 0.5047\n",
            "  Batch 2500/3314, Loss: 0.5036\n",
            "  Batch 3000/3314, Loss: 0.4916\n",
            "Train Loss: 0.5417, Val Loss: 0.8984\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 3/30\n",
            "  Batch 500/3314, Loss: 0.5699\n",
            "  Batch 1000/3314, Loss: 0.5058\n",
            "  Batch 1500/3314, Loss: 0.5095\n",
            "  Batch 2000/3314, Loss: 0.4006\n",
            "  Batch 2500/3314, Loss: 0.4402\n",
            "  Batch 3000/3314, Loss: 0.5156\n",
            "Train Loss: 0.4879, Val Loss: 0.8453\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 4/30\n",
            "  Batch 500/3314, Loss: 0.3975\n",
            "  Batch 1000/3314, Loss: 0.5712\n",
            "  Batch 1500/3314, Loss: 0.3302\n",
            "  Batch 2000/3314, Loss: 0.5054\n",
            "  Batch 2500/3314, Loss: 0.4037\n",
            "  Batch 3000/3314, Loss: 0.4264\n",
            "Train Loss: 0.4520, Val Loss: 0.8302\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 5/30\n",
            "  Batch 500/3314, Loss: 0.4259\n",
            "  Batch 1000/3314, Loss: 0.3639\n",
            "  Batch 1500/3314, Loss: 0.8999\n",
            "  Batch 2000/3314, Loss: 0.5930\n",
            "  Batch 2500/3314, Loss: 0.4904\n",
            "  Batch 3000/3314, Loss: 0.5793\n",
            "Train Loss: 0.4262, Val Loss: 0.8552\n",
            "Learning Rate: 0.001000\n",
            "\n",
            "Sample Predictions:\n",
            "  ✓ ხაიდ                 → ხალიდ                (Target: ხალიდ)\n",
            "  ✗ თქჰულებებისა         → თაბულებებისა         (Target: თქმულებებისა)\n",
            "  ✓ კანტაგანის           → კანტაგანის           (Target: კანტაგანის)\n",
            "  ✓ უვშელა               → უშველა               (Target: უშველა)\n",
            "  ✓ ვერთმფრენის          → ვერთმფრენის          (Target: ვერთმფრენის)\n",
            "  ✗ მემკვიდრდოკბაზე      → მემკვიდრდობაზე       (Target: მემკვიდრეობაზე)\n",
            "  ✗ ფმოქვეყნდა           → ფემოქვეყნდა          (Target: ფამოქვეყნდა)\n",
            "  ✗ პოეტმანი             → პოეტმანი             (Target: პორტიმანი)\n",
            "  ✗ რი                   → რიი                  (Target: არი)\n",
            "  ✗ ასფალგუს             → ასფალგუს             (Target: ასფალგის)\n",
            "\n",
            "Epoch 6/30\n",
            "  Batch 500/3314, Loss: 0.3508\n",
            "  Batch 1000/3314, Loss: 0.3105\n",
            "  Batch 1500/3314, Loss: 0.4005\n",
            "  Batch 2000/3314, Loss: 0.3896\n",
            "  Batch 2500/3314, Loss: 0.3997\n",
            "  Batch 3000/3314, Loss: 0.3849\n",
            "Train Loss: 0.4050, Val Loss: 0.8223\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 7/30\n",
            "  Batch 500/3314, Loss: 0.3970\n",
            "  Batch 1000/3314, Loss: 0.4493\n",
            "  Batch 1500/3314, Loss: 0.3907\n",
            "  Batch 2000/3314, Loss: 0.3487\n",
            "  Batch 2500/3314, Loss: 0.4143\n",
            "  Batch 3000/3314, Loss: 0.3202\n",
            "Train Loss: 0.3896, Val Loss: 0.7999\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 8/30\n",
            "  Batch 500/3314, Loss: 0.3497\n",
            "  Batch 1000/3314, Loss: 0.3476\n",
            "  Batch 1500/3314, Loss: 0.4915\n",
            "  Batch 2000/3314, Loss: 0.3285\n",
            "  Batch 2500/3314, Loss: 0.3190\n",
            "  Batch 3000/3314, Loss: 0.3110\n",
            "Train Loss: 0.3791, Val Loss: 0.8348\n",
            "Learning Rate: 0.001000\n",
            "\n",
            "Epoch 9/30\n",
            "  Batch 500/3314, Loss: 0.3249\n",
            "  Batch 1000/3314, Loss: 0.3237\n",
            "  Batch 1500/3314, Loss: 0.2916\n",
            "  Batch 2000/3314, Loss: 0.3360\n",
            "  Batch 2500/3314, Loss: 0.4461\n",
            "  Batch 3000/3314, Loss: 0.3599\n",
            "Train Loss: 0.3705, Val Loss: 0.7716\n",
            "Learning Rate: 0.001000\n",
            "best model saved!\n",
            "\n",
            "Epoch 10/30\n",
            "  Batch 500/3314, Loss: 0.3554\n",
            "  Batch 1000/3314, Loss: 0.3190\n",
            "  Batch 1500/3314, Loss: 0.3258\n",
            "  Batch 2000/3314, Loss: 0.2963\n",
            "  Batch 2500/3314, Loss: 0.3557\n",
            "  Batch 3000/3314, Loss: 0.3083\n",
            "Train Loss: 0.3627, Val Loss: 0.8049\n",
            "Learning Rate: 0.001000\n",
            "\n",
            "Sample Predictions:\n",
            "  ✗ ხაიდ                 → ხაიდ                 (Target: ხალიდ)\n",
            "  ✓ თქჰულებებისა         → თქმულებებისა         (Target: თქმულებებისა)\n",
            "  ✓ კანტაგანის           → კანტაგანის           (Target: კანტაგანის)\n",
            "  ✗ უვშელა               → უვვშელა              (Target: უშველა)\n",
            "  ✓ ვერთმფრენის          → ვერთმფრენის          (Target: ვერთმფრენის)\n",
            "  ✓ მემკვიდრდოკბაზე      → მემკვიდრეობაზე       (Target: მემკვიდრეობაზე)\n",
            "  ✗ ფმოქვეყნდა           → ფემოქვეყნდა          (Target: ფამოქვეყნდა)\n",
            "  ✗ პოეტმანი             → პოეტმანი             (Target: პორტიმანი)\n",
            "  ✗ რი                   → რი                   (Target: არი)\n",
            "  ✗ ასფალგუს             → ასფალგუს             (Target: ასფალგის)\n",
            "\n",
            "Epoch 11/30\n",
            "  Batch 500/3314, Loss: 0.5422\n",
            "  Batch 1000/3314, Loss: 0.3267\n",
            "  Batch 1500/3314, Loss: 0.3110\n",
            "  Batch 2000/3314, Loss: 0.3807\n",
            "  Batch 2500/3314, Loss: 0.4870\n",
            "  Batch 3000/3314, Loss: 0.3817\n",
            "Train Loss: 0.3561, Val Loss: 0.8020\n",
            "Learning Rate: 0.001000\n",
            "\n",
            "Early stopping - no improvement for 8 epochs\n",
            "\n",
            "Model\n",
            "  Parameters: 25,158,693\n",
            "  Best Val Loss: 0.7716\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# create bigger model\n",
        "model_v2 = Seq2SeqSpellchecker(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=256,      # Was: 128\n",
        "    encoder_dim=512,        # Was: 256\n",
        "    decoder_dim=512,        # Was: 256\n",
        "    attention_dim=256,      # Was: 128\n",
        "    num_layers=3,           # Was: 2\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "\n",
        "# new optimizer\n",
        "optimizer_v2 = optim.Adam(model_v2.parameters(), lr=0.001)\n",
        "scheduler_v2 = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_v2, mode='min', factor=0.5, patience=3\n",
        ")\n",
        "\n",
        "# define the loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "# training history\n",
        "train_losses_v2 = []\n",
        "val_losses_v2 = []\n",
        "best_val_loss_v2 = float('inf')\n",
        "\n",
        "# training loop\n",
        "for epoch in range(1, 31):\n",
        "    print(f\"\\nEpoch {epoch}/30\")\n",
        "\n",
        "    # train\n",
        "    model_v2.train()\n",
        "    epoch_loss = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    for src, src_len, trg in train_loader:\n",
        "        src, src_len, trg = src.to(device), src_len.to(device), trg.to(device)\n",
        "\n",
        "        optimizer_v2.zero_grad()\n",
        "        output = model_v2(src, src_len, trg, teacher_forcing_ratio=0.5)\n",
        "\n",
        "        loss = criterion(output[:, 1:].contiguous().view(-1, len(vocab)),\n",
        "                        trg[:, 1:].contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_v2.parameters(), 1.0)\n",
        "        optimizer_v2.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "        if batch_count % 500 == 0:\n",
        "            print(f\"  Batch {batch_count}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    # validate\n",
        "    model_v2.eval()\n",
        "    val_epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, src_len, trg in val_loader:\n",
        "            src, src_len, trg = src.to(device), src_len.to(device), trg.to(device)\n",
        "            output = model_v2(src, src_len, trg, teacher_forcing_ratio=0)\n",
        "            loss = criterion(output[:, 1:].contiguous().view(-1, len(vocab)),\n",
        "                           trg[:, 1:].contiguous().view(-1))\n",
        "            val_epoch_loss += loss.item()\n",
        "\n",
        "    val_loss = val_epoch_loss / len(val_loader)\n",
        "\n",
        "    train_losses_v2.append(train_loss)\n",
        "    val_losses_v2.append(val_loss)\n",
        "\n",
        "    scheduler_v2.step(val_loss)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "    print(f\"Learning Rate: {optimizer_v2.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # save best model\n",
        "    if val_loss < best_val_loss_v2:\n",
        "        best_val_loss_v2 = val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_v2.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_v2.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "        }, 'checkpoints/best_model.pt')\n",
        "        print(\"best model saved!\")\n",
        "\n",
        "    # test samples every 5 epochs\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"\\nSample Predictions:\")\n",
        "        src, src_len, trg = next(iter(val_loader))\n",
        "        src, src_len = src.to(device), src_len.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model_v2.predict(src[:10], src_len[:10], 30, vocab.sos_idx, vocab.eos_idx)\n",
        "\n",
        "        for i in range(10):\n",
        "            inp = vocab.decode(src[i].cpu().tolist())\n",
        "            tgt = vocab.decode(trg[i].cpu().tolist())\n",
        "            pred = vocab.decode(preds[i].cpu().tolist())\n",
        "            correct = \"✓\" if pred == tgt else \"✗\"\n",
        "            print(f\"  {correct} {inp:20s} \\u2192 {pred:20s} (Target: {tgt})\")\n",
        "\n",
        "    # early stopping if no improvement for 8 epochs\n",
        "    if epoch > 10 and val_loss > min(val_losses_v2[-8:]):\n",
        "        print(f\"\\nEarly stopping - no improvement for 8 epochs\")\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "print(f\"\\nModel\")\n",
        "print(f\"  Parameters: {count_parameters(model_v2):,}\")\n",
        "print(f\"  Best Val Loss: {best_val_loss_v2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WVPcRqZNjV-_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVPcRqZNjV-_",
        "outputId": "50159790-6ddb-419a-858c-fd9c572bdd8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Predictions (CORRECT MODEL):\n",
            "✗ ფეპნი                → ფელნი                (Target: ფერონი)\n",
            "✓ როდწრ                → როდერ                (Target: როდერ)\n",
            "✗ აჰბიუქი              → აბიუქი               (Target: აჰბიუქი)\n",
            "✓ ხუციევფი             → ხუციევი              (Target: ხუციევი)\n",
            "✓ შემოერთევა           → შემოერთება           (Target: შემოერთება)\n",
            "✓ ოცნებბსი             → ოცნებების            (Target: ოცნებების)\n",
            "✗ სჯს                  → სჯის                 (Target: სწჯს)\n",
            "✗ ნშანსვეტია           → ნაშნნსვეტია          (Target: ნიშანსვეტია)\n",
            "✓ ინცეატუი             → ინცესტური            (Target: ინცესტური)\n",
            "✓ წარადიგნონ           → წარადგინონ           (Target: წარადგინონ)\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# load the BEST trained model (model_v2)\n",
        "# first, re-instantiate the model structure\n",
        "model_v2 = Seq2SeqSpellchecker(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=256,\n",
        "    encoder_dim=512,\n",
        "    decoder_dim=512,\n",
        "    attention_dim=256,\n",
        "    num_layers=3,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "checkpoint = torch.load('checkpoints/best_model.pt')\n",
        "model_v2.load_state_dict(checkpoint['model_state_dict'])\n",
        "model_v2.eval()\n",
        "\n",
        "# test with model_v2 (not model!)\n",
        "src, src_len, trg = next(iter(val_loader))\n",
        "src, src_len = src.to(device), src_len.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds = model_v2.predict(src[:10], src_len[:10], 30, vocab.sos_idx, vocab.eos_idx)\n",
        "\n",
        "print(\"Sample Predictions (CORRECT MODEL):\")\n",
        "for i in range(10):\n",
        "    inp = vocab.decode(src[i].cpu().tolist())\n",
        "    tgt = vocab.decode(trg[i].cpu().tolist())\n",
        "    pred = vocab.decode(preds[i].cpu().tolist())\n",
        "    correct = \"✓\" if pred == tgt else \"✗\"\n",
        "    print(f\"{correct} {inp:20s} → {pred:20s} (Target: {tgt})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600b51c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "600b51c3",
        "outputId": "3e643ad0-78a3-42b3-997e-7b67f105b79d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Training Complete!\n",
            "Best validation loss: 0.7716\n"
          ]
        }
      ],
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'vocab_size': len(vocab),\n",
        "    'train_losses': train_losses_v2,\n",
        "    'val_losses': val_losses_v2,\n",
        "}, 'checkpoints/final_model.pt')\n",
        "\n",
        "print(\"\\n Training Complete!\")\n",
        "print(f\"Best validation loss: {best_val_loss_v2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tTCx_8BAlIAP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTCx_8BAlIAP",
        "outputId": "3f4ee9df-ca5c-4d1f-c424-f9e3202c0b2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resuming from epoch 10\n",
            "Starting val loss: 0.7716\n",
            "\n",
            "Epoch 10/40 (TF: 0.60, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.3195\n",
            "  Batch 1000/3314, Loss: 0.3179\n",
            "  Batch 1500/3314, Loss: 0.3451\n",
            "  Batch 2000/3314, Loss: 0.2814\n",
            "  Batch 2500/3314, Loss: 0.3128\n",
            "  Batch 3000/3314, Loss: 0.3377\n",
            "Train: 0.3396, Val: 0.6261\n",
            "✓ Improved 18.9%\n",
            "\n",
            "Samples:\n",
            "  ✗ ფეპნი                → ფელნი               \n",
            "  ✓ როდწრ                → როდერ               \n",
            "  ✗ აჰბიუქი              → ჰაიბუქი             \n",
            "  ✓ ხუციევფი             → ხუციევი             \n",
            "  ✓ შემოერთევა           → შემოერთება          \n",
            "  ✓ ოცნებბსი             → ოცნებების           \n",
            "  ✗ სჯს                  → სჯის                \n",
            "  ✗ ნშანსვეტია           → ნაშნნვვეტია         \n",
            "  ✗ ინცეატუი             → ინცექტური           \n",
            "  ✓ წარადიგნონ           → წარადგინონ          \n",
            "  Accuracy: 5/10 = 50%\n",
            "\n",
            "Epoch 11/40 (TF: 0.57, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2780\n",
            "  Batch 1000/3314, Loss: 0.3599\n",
            "  Batch 1500/3314, Loss: 0.2540\n",
            "  Batch 2000/3314, Loss: 0.3467\n",
            "  Batch 2500/3314, Loss: 0.4689\n",
            "  Batch 3000/3314, Loss: 0.3226\n",
            "Train: 0.3195, Val: 0.6082\n",
            "✓ Improved 21.2%\n",
            "\n",
            "Epoch 12/40 (TF: 0.53, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.3386\n",
            "  Batch 1000/3314, Loss: 0.3022\n",
            "  Batch 1500/3314, Loss: 0.4132\n",
            "  Batch 2000/3314, Loss: 0.2942\n",
            "  Batch 2500/3314, Loss: 0.3702\n",
            "  Batch 3000/3314, Loss: 0.2931\n",
            "Train: 0.3107, Val: 0.5999\n",
            "✓ Improved 22.2%\n",
            "\n",
            "Epoch 13/40 (TF: 0.50, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.4013\n",
            "  Batch 1000/3314, Loss: 0.2516\n",
            "  Batch 1500/3314, Loss: 0.4416\n",
            "  Batch 2000/3314, Loss: 0.3690\n",
            "  Batch 2500/3314, Loss: 0.3336\n",
            "  Batch 3000/3314, Loss: 0.2896\n",
            "Train: 0.3072, Val: 0.5876\n",
            "✓ Improved 23.8%\n",
            "\n",
            "Epoch 14/40 (TF: 0.47, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2703\n",
            "  Batch 1000/3314, Loss: 0.2556\n",
            "  Batch 1500/3314, Loss: 0.2560\n",
            "  Batch 2000/3314, Loss: 0.3024\n",
            "  Batch 2500/3314, Loss: 0.3261\n",
            "  Batch 3000/3314, Loss: 0.3020\n",
            "Train: 0.3023, Val: 0.5698\n",
            "✓ Improved 26.2%\n",
            "\n",
            "Epoch 15/40 (TF: 0.43, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.3052\n",
            "  Batch 1000/3314, Loss: 0.3702\n",
            "  Batch 1500/3314, Loss: 0.3009\n",
            "  Batch 2000/3314, Loss: 0.2832\n",
            "  Batch 2500/3314, Loss: 0.3047\n",
            "  Batch 3000/3314, Loss: 0.2806\n",
            "Train: 0.2989, Val: 0.5694\n",
            "✓ Improved 26.2%\n",
            "\n",
            "Samples:\n",
            "  ✗ ფეპნი                → ფელნი               \n",
            "  ✓ როდწრ                → როდერ               \n",
            "  ✗ აჰბიუქი              → აბიიქქი             \n",
            "  ✓ ხუციევფი             → ხუციევი             \n",
            "  ✓ შემოერთევა           → შემოერთება          \n",
            "  ✓ ოცნებბსი             → ოცნებების           \n",
            "  ✗ სჯს                  → სჯის                \n",
            "  ✗ ნშანსვეტია           → ნაშანსვეტია         \n",
            "  ✗ ინცეატუი             → ინდექტური           \n",
            "  ✓ წარადიგნონ           → წარადგინონ          \n",
            "  Accuracy: 5/10 = 50%\n",
            "\n",
            "Epoch 16/40 (TF: 0.40, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2268\n",
            "  Batch 1000/3314, Loss: 0.2840\n",
            "  Batch 1500/3314, Loss: 0.3127\n",
            "  Batch 2000/3314, Loss: 0.2917\n",
            "  Batch 2500/3314, Loss: 0.1945\n",
            "  Batch 3000/3314, Loss: 0.3088\n",
            "Train: 0.2999, Val: 0.5631\n",
            "✓ Improved 27.0%\n",
            "\n",
            "Epoch 17/40 (TF: 0.37, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2769\n",
            "  Batch 1000/3314, Loss: 0.3286\n",
            "  Batch 1500/3314, Loss: 0.3064\n",
            "  Batch 2000/3314, Loss: 0.3467\n",
            "  Batch 2500/3314, Loss: 0.2622\n",
            "  Batch 3000/3314, Loss: 0.3715\n",
            "Train: 0.2988, Val: 0.5504\n",
            "✓ Improved 28.7%\n",
            "\n",
            "Epoch 18/40 (TF: 0.33, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2825\n",
            "  Batch 1000/3314, Loss: 0.3432\n",
            "  Batch 1500/3314, Loss: 0.2472\n",
            "  Batch 2000/3314, Loss: 0.2293\n",
            "  Batch 2500/3314, Loss: 0.3588\n",
            "  Batch 3000/3314, Loss: 0.2959\n",
            "Train: 0.2976, Val: 0.5402\n",
            "✓ Improved 30.0%\n",
            "\n",
            "Epoch 19/40 (TF: 0.30, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2561\n",
            "  Batch 1000/3314, Loss: 0.2638\n",
            "  Batch 1500/3314, Loss: 0.2839\n",
            "  Batch 2000/3314, Loss: 0.2740\n",
            "  Batch 2500/3314, Loss: 0.2652\n",
            "  Batch 3000/3314, Loss: 0.2345\n",
            "Train: 0.2974, Val: 0.5379\n",
            "✓ Improved 30.3%\n",
            "\n",
            "Epoch 20/40 (TF: 0.27, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.2872\n",
            "  Batch 1000/3314, Loss: 0.2321\n",
            "  Batch 1500/3314, Loss: 0.2756\n",
            "  Batch 2000/3314, Loss: 0.2920\n",
            "  Batch 2500/3314, Loss: 0.2928\n",
            "  Batch 3000/3314, Loss: 0.2921\n",
            "Train: 0.2976, Val: 0.5271\n",
            "✓ Improved 31.7%\n",
            "\n",
            "Samples:\n",
            "  ✗ ფეპნი                → ფელნნი              \n",
            "  ✓ როდწრ                → როდერ               \n",
            "  ✗ აჰბიუქი              → ჰაბიუქი             \n",
            "  ✓ ხუციევფი             → ხუციევი             \n",
            "  ✓ შემოერთევა           → შემოერთება          \n",
            "  ✓ ოცნებბსი             → ოცნებების           \n",
            "  ✗ სჯს                  → სუს                 \n",
            "  ✗ ნშანსვეტია           → ნაშანსვეტია         \n",
            "  ✗ ინცეატუი             → ინდექტური           \n",
            "  ✓ წარადიგნონ           → წარადგინონ          \n",
            "  Accuracy: 5/10 = 50%\n",
            "\n",
            "Epoch 21/40 (TF: 0.23, LR: 0.000200)\n",
            "  Batch 500/3314, Loss: 0.4395\n",
            "  Batch 1000/3314, Loss: 0.2770\n",
            "  Batch 1500/3314, Loss: 0.2530\n",
            "  Batch 2000/3314, Loss: 0.3956\n",
            "  Batch 2500/3314, Loss: 0.4283\n",
            "  Batch 3000/3314, Loss: 0.3778\n",
            "Train: 0.2971, Val: 0.5287\n",
            "\n",
            "Early stop\n",
            "\n",
            "Best: 0.7716 → 0.5271\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# load best model\n",
        "checkpoint = torch.load('checkpoints/best_model.pt')\n",
        "model_v2.load_state_dict(checkpoint['model_state_dict'])\n",
        "model_v2.train()\n",
        "\n",
        "# optimizer\n",
        "optimizer_continued = optim.Adam(model_v2.parameters(), lr=0.0002)\n",
        "scheduler_continued = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_continued, mode='min', factor=0.5, patience=2\n",
        ")\n",
        "\n",
        "# define the loss function (criterion) - re-added for continuity\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "# start fresh history from this checkpoint\n",
        "start_epoch = checkpoint.get('epoch', 9)  # checkpoint was epoch 9\n",
        "best_val_loss_v2 = checkpoint.get('val_loss', 0.7716)\n",
        "\n",
        "train_losses_continued = []\n",
        "val_losses_continued = []\n",
        "best_val_loss_continued = best_val_loss_v2\n",
        "\n",
        "print(f\"Resuming from epoch {start_epoch + 1}\")\n",
        "print(f\"Starting val loss: {best_val_loss_v2:.4f}\")\n",
        "\n",
        "# continue training\n",
        "for epoch in range(start_epoch + 1, 41):\n",
        "    tf_ratio = max(0.2, 0.6 - (epoch - start_epoch - 1) / 30)\n",
        "\n",
        "    print(f\"\\nEpoch {epoch}/40 (TF: {tf_ratio:.2f}, LR: {optimizer_continued.param_groups[0]['lr']:.6f})\")\n",
        "\n",
        "    # train\n",
        "    model_v2.train()\n",
        "    epoch_loss = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    for src, src_len, trg in train_loader:\n",
        "        src, src_len, trg = src.to(device), src_len.to(device), trg.to(device)\n",
        "\n",
        "        optimizer_continued.zero_grad()\n",
        "        output = model_v2(src, src_len, trg, teacher_forcing_ratio=tf_ratio)\n",
        "\n",
        "        loss = criterion(output[:, 1:].contiguous().view(-1, len(vocab)),\n",
        "                        trg[:, 1:].contiguous().view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model_v2.parameters(), 1.0)\n",
        "        optimizer_continued.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "        if batch_count % 500 == 0:\n",
        "            print(f\"  Batch {batch_count}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    train_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    # validate\n",
        "    model_v2.eval()\n",
        "    val_epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, src_len, trg in val_loader:\n",
        "            src, src_len, trg = src.to(device), src_len.to(device), trg.to(device)\n",
        "            output = model_v2(src, src_len, trg, teacher_forcing_ratio=0)\n",
        "            loss = criterion(output[:, 1:].contiguous().view(-1, len(vocab)),\n",
        "                           trg[:, 1:].contiguous().view(-1))\n",
        "            val_epoch_loss += loss.item()\n",
        "\n",
        "    val_loss = val_epoch_loss / len(val_loader)\n",
        "\n",
        "    train_losses_continued.append(train_loss)\n",
        "    val_losses_continued.append(val_loss)\n",
        "\n",
        "    scheduler_continued.step(val_loss)\n",
        "\n",
        "    print(f\"Train: {train_loss:.4f}, Val: {val_loss:.4f}\")\n",
        "\n",
        "    # save if improved\n",
        "    if val_loss < best_val_loss_continued:\n",
        "        best_val_loss_continued = val_loss\n",
        "        improvement = (best_val_loss_v2 - val_loss) / best_val_loss_v2 * 100\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_v2.state_dict(),\n",
        "            'optimizer_state_dict': optimizer_continued.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss,\n",
        "            'train_losses': train_losses_continued,\n",
        "            'val_losses': val_losses_continued,\n",
        "        }, 'checkpoints/best_model_continued.pt')\n",
        "        print(f\"✓ Improved {improvement:.1f}%\")\n",
        "\n",
        "    # test every 5 epochs\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"\\nSamples:\")\n",
        "        src, src_len, trg = next(iter(val_loader))\n",
        "        src, src_len = src.to(device), src_len.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            preds = model_v2.predict(src[:10], src_len[:10], 30, vocab.sos_idx, vocab.eos_idx)\n",
        "\n",
        "        correct = sum(1 for i in range(10) if vocab.decode(preds[i].cpu().tolist()) == vocab.decode(trg[i].cpu().tolist()))\n",
        "        for i in range(10):\n",
        "            inp = vocab.decode(src[i].cpu().tolist())\n",
        "            tgt = vocab.decode(trg[i].cpu().tolist())\n",
        "            pred = vocab.decode(preds[i].cpu().tolist())\n",
        "            marker = \"✓\" if pred == tgt else \"✗\"\n",
        "            print(f\"  {marker} {inp:20s} → {pred:20s}\")\n",
        "        print(f\"  Accuracy: {correct}/10 = {correct*10}%\")\n",
        "\n",
        "    # early stopping\n",
        "    if len(val_losses_continued) >= 10 and val_loss > min(val_losses_continued[-10:]):\n",
        "        print(\"\\nEarly stop\")\n",
        "        break\n",
        "\n",
        "print(f\"\\nBest: {best_val_loss_v2:.4f} → {best_val_loss_continued:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8dbd2d56",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded the last 11 train and 11 val loss values.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "checkpoint = torch.load('checkpoints/best_model_continued.pt', map_location=torch.device('cpu'))\n",
        "train_losses_v2 = checkpoint.get('train_losses', [])\n",
        "val_losses_v2 = checkpoint.get('val_losses', [])\n",
        "print(f\"Loaded the last {len(train_losses_v2)} train and {len(val_losses_v2)} val loss values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e38f8918",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses_v2, label='Train Loss')\n",
        "plt.plot(val_losses_v2, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig('checkpoints/training_curves.png', dpi=150)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
